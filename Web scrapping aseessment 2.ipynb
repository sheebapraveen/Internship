{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf9c350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) python program to scrape data for “Data Analyst” Job position in “Bangalore” location, job-title, \n",
    " job-location, company_name, experience_required using naukri.com "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00fe55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's first install the selenium library\n",
    "! pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "61af0466",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's now import all the required libraries.\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5e66e760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: webdriver-manager in c:\\anaconda\\lib\\site-packages (3.8.3)\n",
      "Requirement already satisfied: tqdm in c:\\anaconda\\lib\\site-packages (from webdriver-manager) (4.62.3)\n",
      "Requirement already satisfied: requests in c:\\anaconda\\lib\\site-packages (from webdriver-manager) (2.26.0)\n",
      "Requirement already satisfied: python-dotenv in c:\\anaconda\\lib\\site-packages (from webdriver-manager) (0.21.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\anaconda\\lib\\site-packages (from requests->webdriver-manager) (3.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\anaconda\\lib\\site-packages (from requests->webdriver-manager) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\anaconda\\lib\\site-packages (from requests->webdriver-manager) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\anaconda\\lib\\site-packages (from requests->webdriver-manager) (2.0.4)\n",
      "Requirement already satisfied: colorama in c:\\anaconda\\lib\\site-packages (from tqdm->webdriver-manager) (0.4.4)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install webdriver-manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ecd7a9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's first connect to the web driver\n",
    "driver =webdriver.Chrome(r\"C:\\Users\\Praveen kumar\\Downloads\\chromedriver_win32\\chromedriver.exe\")\n",
    "driver.get(\"https://www.naukri.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "978c48a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "designation=driver.find_element(By.CLASS_NAME,\"suggestor-input\")\n",
    "designation.send_keys('Data Analyst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9621a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "location=driver.find_element(By.XPATH,\"/html/body/div[1]/div[6]/div/div/div[5]/div/div/div/input\")\n",
    "location.send_keys('Bangalore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dfb2c653",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.CLASS_NAME,\"qsbSubmit\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aac68fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e75567b",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_tags=driver.find_elements(By.XPATH,'//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in  title_tags[0:10]:\n",
    " title = i.text\n",
    " job_title.append(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0cf6750a",
   "metadata": {},
   "outputs": [],
   "source": [
    "location_tags=driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi location\"]')\n",
    "for i in  location_tags[0:10]:\n",
    " location = i.text\n",
    " job_location.append(location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "278adeb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "company_tags=driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in  company_tags[0:10]:\n",
    " company = i.text\n",
    " company_name.append(company)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "57baa62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_tags=driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]')\n",
    "for i in  exp_tags[0:10]:\n",
    " exp= i.text\n",
    " experience_required.append(exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "17d66c86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(job_title),len(job_location),len(company_name),len(experience_required))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "28c4f7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame({})\n",
    "df['job_title']=job_title[:10]\n",
    "df['company_name']=company_name[:10]\n",
    "df['experience_required']=experience_required[:10]\n",
    "df['job_location']=job_location[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "80c5f4b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>company_name</th>\n",
       "      <th>experience_required</th>\n",
       "      <th>job_location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Analyst - Python/Artificial Intelligence</td>\n",
       "      <td>iMindYourBusiness</td>\n",
       "      <td>0-2 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Contractual Hiring For Top MNC || Business Dat...</td>\n",
       "      <td>TeamLease</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Programmer / Data Analyst</td>\n",
       "      <td>Frost &amp; Sullivan</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Hyderabad/Secund...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HCL hiring For Data Analyst</td>\n",
       "      <td>HCL Technologies</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru, Pune, Chennai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Market Data Senior Analyst</td>\n",
       "      <td>Allegis Services India Pvt. Ltd.</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Analyst - Java/Python</td>\n",
       "      <td>Career Infosystem</td>\n",
       "      <td>4-8 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Analyst - SQL/ Database Maintenance</td>\n",
       "      <td>Career Infosystem</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Lead Data Analyst - US MNC (analytics)</td>\n",
       "      <td>Aspyra HR Services</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru, Gurgaon/Gurugram\\n(WFH du...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data analyst / Data analytics -- US MNC (analy...</td>\n",
       "      <td>Aspyra HR Services</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru, Gurgaon/Gurugram\\n(WFH du...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Analyst - Ops</td>\n",
       "      <td>Pylon Management Consulting Pvt Ltd</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           job_title  \\\n",
       "0      Data Analyst - Python/Artificial Intelligence   \n",
       "1  Contractual Hiring For Top MNC || Business Dat...   \n",
       "2                          Programmer / Data Analyst   \n",
       "3                        HCL hiring For Data Analyst   \n",
       "4                         Market Data Senior Analyst   \n",
       "5                         Data Analyst - Java/Python   \n",
       "6           Data Analyst - SQL/ Database Maintenance   \n",
       "7             Lead Data Analyst - US MNC (analytics)   \n",
       "8  Data analyst / Data analytics -- US MNC (analy...   \n",
       "9                                 Data Analyst - Ops   \n",
       "\n",
       "                          company_name experience_required  \\\n",
       "0                    iMindYourBusiness             0-2 Yrs   \n",
       "1                            TeamLease             5-8 Yrs   \n",
       "2                     Frost & Sullivan             3-7 Yrs   \n",
       "3                     HCL Technologies             3-8 Yrs   \n",
       "4     Allegis Services India Pvt. Ltd.             2-5 Yrs   \n",
       "5                    Career Infosystem             4-8 Yrs   \n",
       "6                    Career Infosystem             5-8 Yrs   \n",
       "7                   Aspyra HR Services            5-10 Yrs   \n",
       "8                   Aspyra HR Services             3-8 Yrs   \n",
       "9  Pylon Management Consulting Pvt Ltd             2-5 Yrs   \n",
       "\n",
       "                                        job_location  \n",
       "0  Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...  \n",
       "1                                Bangalore/Bengaluru  \n",
       "2  Bangalore/Bengaluru, Kolkata, Hyderabad/Secund...  \n",
       "3                 Bangalore/Bengaluru, Pune, Chennai  \n",
       "4                                Bangalore/Bengaluru  \n",
       "5  Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...  \n",
       "6                                Bangalore/Bengaluru  \n",
       "7  Bangalore/Bengaluru, Gurgaon/Gurugram\\n(WFH du...  \n",
       "8  Bangalore/Bengaluru, Gurgaon/Gurugram\\n(WFH du...  \n",
       "9                                Bangalore/Bengaluru  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7c9b0fdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"14425ad275234149d0684af6a25d9bf9\", element=\"bed1386a-ef02-40db-b8db-276ba99d3fa9\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"14425ad275234149d0684af6a25d9bf9\", element=\"dd681df5-4d17-424e-9201-de4198da7bfa\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"14425ad275234149d0684af6a25d9bf9\", element=\"2bbb0615-00d0-47cc-ad05-5399699f6b92\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"14425ad275234149d0684af6a25d9bf9\", element=\"bd5bc887-912d-4eb5-b95f-3c86a9411ee3\")>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#to fetch the URL\n",
    "url=driver.find_elements(By.XPATH,'//a[@class=\"title fw500 ellipsis\"]')\n",
    "url[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "24d95394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.naukri.com/job-listings-data-analyst-python-artificial-intelligence-imindyourbusiness-kolkata-mumbai-hyderabad-secunderabad-lucknow-chennai-ahmedabad-bangalore-bengaluru-delhi-ncr-0-to-2-years-080922903962\n",
      "https://www.naukri.com/job-listings-contractual-hiring-for-top-mnc-business-data-analyst-bangalore-teamlease-servcies-limited-bangalore-bengaluru-5-to-8-years-030622001010\n",
      "https://www.naukri.com/job-listings-programmer-data-analyst-frost-and-sullivan-india-private-limited-kolkata-hyderabad-secunderabad-pune-ahmedabad-bangalore-bengaluru-delhi-ncr-mumbai-all-areas-karnataka-tamil-nadu-3-to-7-years-090922001343\n",
      "https://www.naukri.com/job-listings-hcl-hiring-for-data-analyst-hcl-technologies-limited-pune-chennai-bangalore-bengaluru-3-to-8-years-080922005378\n"
     ]
    }
   ],
   "source": [
    "for i in url[0:4]:\n",
    " print(i.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6b02e4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_titles=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a5677e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "start=0\n",
    "end=2\n",
    "for page in range(start,end):\n",
    " titles=driver.find_elements(By.XPATH,'//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in titles:\n",
    " job_titles.append(i.text)\n",
    "next_button=driver.find_element(By.XPATH,'//a[@class=\"fright fs14 btn-secondary br2\"]')\n",
    "next_button.click()\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c3aa7794",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(job_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ffe5049a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data Analyst - Python/Artificial Intelligence',\n",
       " 'Contractual Hiring For Top MNC || Business Data Analyst || Bangalore',\n",
       " 'Programmer / Data Analyst',\n",
       " 'HCL hiring For Data Analyst',\n",
       " 'Market Data Senior Analyst',\n",
       " 'Data Analyst - Java/Python',\n",
       " 'Data Analyst - SQL/ Database Maintenance',\n",
       " 'Lead Data Analyst - US MNC (analytics)',\n",
       " 'Data analyst / Data analytics -- US MNC (analytics)',\n",
       " 'Data Analyst - Ops',\n",
       " 'Immediate opening For Data Analyst @ Bangalore',\n",
       " 'Associate Data Analyst',\n",
       " 'Associate Data Analyst',\n",
       " 'Customer Data Analyst',\n",
       " 'Sr. Data Analyst',\n",
       " 'Senior Data Analyst',\n",
       " 'Senior Data Analyst - Risk Assessment | Cigna',\n",
       " 'Data Analyst - Decision Science',\n",
       " 'Data Analyst']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "0c288aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2)python program to scrape data for “Data Scientist” Job position in “Bangalore” location, job-title, job-location, company_name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "59460fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver =webdriver.Chrome(r\"C:\\Users\\Praveen kumar\\Downloads\\chromedriver_win32\\chromedriver.exe\")\n",
    "driver.get(\"https://www.naukri.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2b3439fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "designation=driver.find_element(By.CLASS_NAME,\"suggestor-input\")\n",
    "designation.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7ace1a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "location=driver.find_element(By.XPATH,\"/html/body/div[1]/div[6]/div/div/div[5]/div/div/div/input\")\n",
    "location.send_keys('Bangalore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f6cd8517",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.CLASS_NAME,\"qsbSubmit\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "77368990",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "59fdd8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_tags=driver.find_elements(By.XPATH,'//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in  title_tags[0:10]:\n",
    " title = i.text\n",
    " job_title.append(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7e6144a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "location_tags=driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi location\"]')\n",
    "for i in  location_tags[0:10]:\n",
    " location = i.text\n",
    " job_location.append(location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "32ef075f",
   "metadata": {},
   "outputs": [],
   "source": [
    "company_tags=driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in  company_tags[0:10]:\n",
    " company = i.text\n",
    " company_name.append(company)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f8333bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_tags=driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]')\n",
    "for i in  exp_tags[0:10]:\n",
    " exp= i.text\n",
    " experience_required.append(exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5ee7adc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(job_title),len(job_location),len(company_name),len(experience_required))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "60656fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame({})\n",
    "df['job_title']=job_title[:10]\n",
    "df['company_name']=company_name[:10]\n",
    "df['experience_required']=experience_required[:10]\n",
    "df['job_location']=job_location[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "dd26b598",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>company_name</th>\n",
       "      <th>experience_required</th>\n",
       "      <th>job_location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Job Opportunity on Data Science_ Python with T...</td>\n",
       "      <td>Tech Mahindra</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Hyderabad/Secund...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Assistant Manager - Data Science</td>\n",
       "      <td>CitiusTech</td>\n",
       "      <td>5-9 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai, Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Analystics &amp; Modeling Specialist</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>6-8 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hiring For DATA Scientist @ NTT DATA Business ...</td>\n",
       "      <td>NTT DATA Business Solutions Private Limited</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru, Noida, Hyderabad/Secunder...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist/AIML Engineer</td>\n",
       "      <td>upGrad</td>\n",
       "      <td>0-2 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai, Hyderabad/Secunde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Science Consultant</td>\n",
       "      <td>ZS Associates India Pvt Ltd</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru, Pune, Gurgaon/Gurugram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>GlobalLogic</td>\n",
       "      <td>8-10 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru, Noida, Nagpur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>GlobalLogic</td>\n",
       "      <td>8-9 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Lead ML Scientist</td>\n",
       "      <td>Fractal Analytics</td>\n",
       "      <td>6-10 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Tcs Hiring For Data Scientist</td>\n",
       "      <td>TATA CONSULTANCY SERVICES (TCS)</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru, Chennai, Mumbai (All Areas)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           job_title  \\\n",
       "0  Job Opportunity on Data Science_ Python with T...   \n",
       "1                   Assistant Manager - Data Science   \n",
       "2                   Analystics & Modeling Specialist   \n",
       "3  Hiring For DATA Scientist @ NTT DATA Business ...   \n",
       "4                       Data Scientist/AIML Engineer   \n",
       "5                            Data Science Consultant   \n",
       "6                                     Data Scientist   \n",
       "7                                     Data Scientist   \n",
       "8                                  Lead ML Scientist   \n",
       "9                      Tcs Hiring For Data Scientist   \n",
       "\n",
       "                                  company_name experience_required  \\\n",
       "0                                Tech Mahindra             4-9 Yrs   \n",
       "1                                   CitiusTech             5-9 Yrs   \n",
       "2                                    Accenture             6-8 Yrs   \n",
       "3  NTT DATA Business Solutions Private Limited             4-9 Yrs   \n",
       "4                                       upGrad             0-2 Yrs   \n",
       "5                  ZS Associates India Pvt Ltd             3-8 Yrs   \n",
       "6                                  GlobalLogic            8-10 Yrs   \n",
       "7                                  GlobalLogic             8-9 Yrs   \n",
       "8                            Fractal Analytics            6-10 Yrs   \n",
       "9              TATA CONSULTANCY SERVICES (TCS)             3-8 Yrs   \n",
       "\n",
       "                                        job_location  \n",
       "0  Bangalore/Bengaluru, Kolkata, Hyderabad/Secund...  \n",
       "1                  Bangalore/Bengaluru, Mumbai, Pune  \n",
       "2  Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...  \n",
       "3  Bangalore/Bengaluru, Noida, Hyderabad/Secunder...  \n",
       "4  Bangalore/Bengaluru, Mumbai, Hyderabad/Secunde...  \n",
       "5        Bangalore/Bengaluru, Pune, Gurgaon/Gurugram  \n",
       "6                 Bangalore/Bengaluru, Noida, Nagpur  \n",
       "7                                Bangalore/Bengaluru  \n",
       "8                        Bangalore/Bengaluru, Mumbai  \n",
       "9   Bangalore/Bengaluru, Chennai, Mumbai (All Areas)  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ceeb80d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"acc09f1163d2b2b8af4257987dcd390a\", element=\"509246f9-734a-4810-8c53-2bb7e375b109\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"acc09f1163d2b2b8af4257987dcd390a\", element=\"6aaa3177-2845-4e6a-ab58-a958d9776f84\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"acc09f1163d2b2b8af4257987dcd390a\", element=\"43b57302-3e91-4c4d-b651-8f8a62221938\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"acc09f1163d2b2b8af4257987dcd390a\", element=\"e0b1a512-06e4-4b14-9e35-234b1514f7a9\")>]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#to fetch the URL\n",
    "url=driver.find_elements(By.XPATH,'//a[@class=\"title fw500 ellipsis\"]')\n",
    "url[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f69cfe8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.naukri.com/job-listings-opportunity-on-data-science-python-with-techmahindra-tech-mahindra-ltd-kolkata-hyderabad-secunderabad-pune-chennai-bangalore-bengaluru-delhi-ncr-mumbai-all-areas-4-to-9-years-050922007987\n",
      "https://www.naukri.com/job-listings-assistant-manager-data-science-citiustech-healthcare-technology-pvt-ltd-mumbai-pune-bangalore-bengaluru-5-to-9-years-010822004921\n",
      "https://www.naukri.com/job-listings-analystics-modeling-specialist-accenture-solutions-pvt-ltd-kolkata-mumbai-hyderabad-secunderabad-pune-chennai-bangalore-bengaluru-delhi-ncr-6-to-8-years-300822902414\n",
      "https://www.naukri.com/job-listings-hiring-for-data-scientist-ntt-data-business-solution-india-ntt-data-business-solutions-private-limited-noida-hyderabad-secunderabad-pune-gurgaon-gurugram-chennai-bangalore-bengaluru-mumbai-all-areas-4-to-9-years-200722003814\n"
     ]
    }
   ],
   "source": [
    "for i in url[0:4]:\n",
    " print(i.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ac7e53c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_titles=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b8704b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "start=0\n",
    "end=2\n",
    "for page in range(start,end):\n",
    " titles=driver.find_elements(By.XPATH,'//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in titles:\n",
    " job_titles.append(i.text)\n",
    "next_button=driver.find_element(By.XPATH,'//a[@class=\"fright fs14 btn-secondary br2\"]')\n",
    "next_button.click()\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0aeed098",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(job_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "893c1336",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Job Opportunity on Data Science_ Python with Techmahindra',\n",
       " 'Assistant Manager - Data Science',\n",
       " 'Analystics & Modeling Specialist',\n",
       " 'Hiring For DATA Scientist @ NTT DATA Business Solution India',\n",
       " 'Data Scientist/AIML Engineer',\n",
       " 'Data Science Consultant',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Lead ML Scientist',\n",
       " 'Tcs Hiring For Data Scientist',\n",
       " 'Data Scientist - II',\n",
       " 'Data Scientist - A.P. Maersk',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Principal Data Scientist']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "27f2fe0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3)phython program to scrape data using the filters available on the webpage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "cb33d2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's first connect to the web driver\n",
    "driver =webdriver.Chrome(r\"C:\\Users\\Praveen kumar\\Downloads\\chromedriver_win32\\chromedriver.exe\")\n",
    "driver.get(\"https://www.naukri.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "98929e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "designation=driver.find_element(By.CLASS_NAME,\"suggestor-input\")\n",
    "designation.send_keys('Data Scientist')\n",
    "search=driver.find_element(By.CLASS_NAME,\"qsbSubmit\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "cce106e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "location=driver.find_element(By.XPATH,\"/html/body/div[1]/div[4]/div/section[1]/div[2]/div[5]/div[2]/div[3]/label/p\")\n",
    "location.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "1954ecb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "salary=driver.find_element(By.XPATH,\"/html/body/div[1]/div[4]/div/section[1]/div[2]/div[6]/div[2]/div[2]/label/p\")\n",
    "salary.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "78a2c913",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "Salary_exp=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "e7ad83fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_tags=driver.find_elements(By.XPATH,'//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in title_tags[0:10]:\n",
    " title = i.text\n",
    " job_title.append(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "a5e97acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "location_tags=driver.find_elements(By.XPATH,\"/html/body/div[1]/div[4]/div/section[1]/div[2]/div[5]/div[2]/div[3]/label/p\")\n",
    "for i in location_tags[0:10]:\n",
    " location = i.text\n",
    " job_location.append(location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "6252951b",
   "metadata": {},
   "outputs": [],
   "source": [
    "company_tags=driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in company_tags[0:10]:\n",
    " company = i.text\n",
    " company_name.append(company)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "534816b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_exp=driver.find_elements(By.XPATH,'//p[@class=\"grey-text lH20 fleft ml-8 txtLbl\"]')\n",
    "for i in  salary_exp[0:10]:\n",
    " exp= i.text\n",
    " Salary_exp.append(exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "5b8bbe31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(job_title),len(company_name),len(experience_required))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "9a159b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame({})\n",
    "df['job_title']=job_title[:10]\n",
    "df['company_name']=company_name[:10]\n",
    "df['Salary_exp']=Salary_exp[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "8ba0a7e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>company_name</th>\n",
       "      <th>Salary_exp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>GlobalLogic</td>\n",
       "      <td>Remote\\n(1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DigitalBCG GAMMA Data Scientist</td>\n",
       "      <td>Boston Consulting Group</td>\n",
       "      <td>Delhi / NCR\\n(21)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Optum</td>\n",
       "      <td>Bangalore/Bengaluru\\n(48)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist / Chat-bot Developer</td>\n",
       "      <td>Big Seo Buzz</td>\n",
       "      <td>Chennai\\n(15)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>R Systems International</td>\n",
       "      <td>Data Scientist\\n(21)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist - Predictive Analytics</td>\n",
       "      <td>Confidential</td>\n",
       "      <td>Back End Developer\\n(5413)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist For Healthcare Product team</td>\n",
       "      <td>SECUREKLOUD TECHNOLOGIES</td>\n",
       "      <td>Business Development Manager (BDM)\\n(2212)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist - Engine Algorithm</td>\n",
       "      <td>Primo Hiring</td>\n",
       "      <td>Other\\n(1803)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Feedback Infra</td>\n",
       "      <td>3-6 Lakhs\\n(21)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>4i Odc</td>\n",
       "      <td>6-10 Lakhs\\n(81)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    job_title              company_name  \\\n",
       "0                              Data Scientist               GlobalLogic   \n",
       "1             DigitalBCG GAMMA Data Scientist   Boston Consulting Group   \n",
       "2                              Data Scientist                     Optum   \n",
       "3         Data Scientist / Chat-bot Developer              Big Seo Buzz   \n",
       "4                         Lead Data Scientist   R Systems International   \n",
       "5       Data Scientist - Predictive Analytics              Confidential   \n",
       "6  Data Scientist For Healthcare Product team  SECUREKLOUD TECHNOLOGIES   \n",
       "7           Data Scientist - Engine Algorithm              Primo Hiring   \n",
       "8                              Data Scientist            Feedback Infra   \n",
       "9                              Data Scientist                    4i Odc   \n",
       "\n",
       "                                   Salary_exp  \n",
       "0                                 Remote\\n(1)  \n",
       "1                           Delhi / NCR\\n(21)  \n",
       "2                   Bangalore/Bengaluru\\n(48)  \n",
       "3                               Chennai\\n(15)  \n",
       "4                        Data Scientist\\n(21)  \n",
       "5                  Back End Developer\\n(5413)  \n",
       "6  Business Development Manager (BDM)\\n(2212)  \n",
       "7                               Other\\n(1803)  \n",
       "8                             3-6 Lakhs\\n(21)  \n",
       "9                            6-10 Lakhs\\n(81)  "
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "3571f54b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"af77d59c04a801a01eac21e93626af32\", element=\"da3ac8ac-4061-439a-ae26-b66276d080b0\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"af77d59c04a801a01eac21e93626af32\", element=\"3caf56e3-022d-4d6d-bc07-9ba96a8a66d4\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"af77d59c04a801a01eac21e93626af32\", element=\"56ad3841-fe89-496d-97ef-c29ee5979533\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"af77d59c04a801a01eac21e93626af32\", element=\"364161a8-b747-4a2a-9005-3ce19458baf5\")>]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#to fetch the URL\n",
    "url=driver.find_elements(By.XPATH,'//a[@class=\"title fw500 ellipsis\"]')\n",
    "url[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "414e7d16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.naukri.com/job-listings-data-scientist-globallogic-india-private-limited-noida-nagpur-bangalore-bengaluru-8-to-10-years-090922005067\n",
      "https://www.naukri.com/job-listings-digitalbcg-gamma-data-scientist-boston-consulting-group-new-delhi-bangalore-bengaluru-2-to-5-years-040722500013\n",
      "https://www.naukri.com/job-listings-data-scientist-optum-global-solutions-india-private-limited-gurgaon-gurugram-2-to-7-years-060922903456\n",
      "https://www.naukri.com/job-listings-data-scientist-chat-bot-developer-big-seo-buzz-new-delhi-bangalore-bengaluru-mumbai-all-areas-3-to-7-years-250522010475\n"
     ]
    }
   ],
   "source": [
    "for i in url[0:4]:\n",
    " print(i.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "3140b452",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data Scientist',\n",
       " 'DigitalBCG GAMMA Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist / Chat-bot Developer',\n",
       " 'Lead Data Scientist',\n",
       " 'Data Scientist - Predictive Analytics',\n",
       " 'Data Scientist For Healthcare Product team',\n",
       " 'Data Scientist - Engine Algorithm',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist']"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "7f04b8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4)phython program to Scrape data of first 100 sunglasses listings on flipkart.com."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "85cca0ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\anaconda\\lib\\site-packages (4.4.3)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\anaconda\\lib\\site-packages (from selenium) (0.21.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\anaconda\\lib\\site-packages (from selenium) (0.9.2)\n",
      "Requirement already satisfied: urllib3[socks]~=1.26 in c:\\anaconda\\lib\\site-packages (from selenium) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\anaconda\\lib\\site-packages (from selenium) (2021.10.8)\n",
      "Requirement already satisfied: outcome in c:\\anaconda\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: idna in c:\\anaconda\\lib\\site-packages (from trio~=0.17->selenium) (3.2)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\anaconda\\lib\\site-packages (from trio~=0.17->selenium) (1.14.6)\n",
      "Requirement already satisfied: async-generator>=1.9 in c:\\anaconda\\lib\\site-packages (from trio~=0.17->selenium) (1.10)\n",
      "Requirement already satisfied: sortedcontainers in c:\\anaconda\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\anaconda\\lib\\site-packages (from trio~=0.17->selenium) (21.2.0)\n",
      "Requirement already satisfied: sniffio in c:\\anaconda\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: pycparser in c:\\anaconda\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.20)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\anaconda\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\anaconda\\lib\\site-packages (from urllib3[socks]~=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\anaconda\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.13.0)\n"
     ]
    }
   ],
   "source": [
    "# let's first install the selenium library\n",
    "! pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "73c98693",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's now import all the required libraries.\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "f9845fad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: webdriver-manager in c:\\anaconda\\lib\\site-packages (3.8.3)\n",
      "Requirement already satisfied: python-dotenv in c:\\anaconda\\lib\\site-packages (from webdriver-manager) (0.21.0)\n",
      "Requirement already satisfied: tqdm in c:\\anaconda\\lib\\site-packages (from webdriver-manager) (4.62.3)\n",
      "Requirement already satisfied: requests in c:\\anaconda\\lib\\site-packages (from webdriver-manager) (2.26.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\anaconda\\lib\\site-packages (from requests->webdriver-manager) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\anaconda\\lib\\site-packages (from requests->webdriver-manager) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\anaconda\\lib\\site-packages (from requests->webdriver-manager) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\anaconda\\lib\\site-packages (from requests->webdriver-manager) (3.2)\n",
      "Requirement already satisfied: colorama in c:\\anaconda\\lib\\site-packages (from tqdm->webdriver-manager) (0.4.4)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install webdriver-manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "d921b62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's first connect to the web driver\n",
    "driver =webdriver.Chrome(r\"C:\\Users\\Praveen kumar\\Downloads\\chromedriver_win32\\chromedriver.exe\")\n",
    "driver.get(\"https://www.flipkart.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "63a43a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "product=driver.find_element(By.CLASS_NAME,\"_3704LK\")\n",
    "product.send_keys('Sunglasses')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "1767f5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.CLASS_NAME,\"_34RNph\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "0daa1ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "B_name=[]\n",
    "Price_tag=[]\n",
    "P_desc=[]\n",
    "Discount=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "4bea744d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    b_name=driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')\n",
    "    p_desc=driver.find_elements(By.XPATH,'//a[@class=\"IRpwTa\"]')\n",
    "    price_tag =driver.find_elements(By.XPATH,'//div[@class=\"_25b18c\"]')\n",
    "    discount=driver.find_elements(By.XPATH,'//div[@class=\"_3Ay6Sb\"]')\n",
    "    \n",
    "    for j  in b_name:\n",
    "        B_name.append(j.text)\n",
    "    B_name[:100]    \n",
    "    \n",
    "    \n",
    "    \n",
    "    for k in p_desc:\n",
    "        P_desc.append(k.text)\n",
    "    P_desc[:100] \n",
    "    \n",
    "    \n",
    "    for l in price_tag:\n",
    "        Price_tag.append(l.text)\n",
    "    Price_tag[:100] \n",
    "    \n",
    "    \n",
    "    for t in discount:\n",
    "        Discount.append(t.text)\n",
    "    Discount[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "38740778",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AISLIN',\n",
       " 'VINCENT CHASE',\n",
       " 'New Specs',\n",
       " 'PIRASO',\n",
       " 'PHENOMENAL',\n",
       " 'LIZA ANGEL',\n",
       " 'SUNBEE',\n",
       " 'VINCENT CHASE',\n",
       " 'SHAAH COLLECTIONS',\n",
       " 'Fastrack',\n",
       " 'VINCENT CHASE',\n",
       " 'VINCENT CHASE',\n",
       " 'CRYSTAL CART',\n",
       " 'Sewell',\n",
       " 'Elligator',\n",
       " 'PIRASO',\n",
       " 'PIRASO',\n",
       " 'ROYAL SON',\n",
       " 'Rich Club',\n",
       " 'PIRASO',\n",
       " 'ROZZETTA CRAFT',\n",
       " 'Roadster',\n",
       " 'ROZZETTA CRAFT',\n",
       " 'Lee Topper',\n",
       " 'SRPM',\n",
       " 'ROYAL SON',\n",
       " 'PIRASO',\n",
       " 'PIRASO',\n",
       " 'New Specs',\n",
       " 'New Specs',\n",
       " 'Singco India',\n",
       " 'elegante',\n",
       " 'CRYSTAL CART',\n",
       " 'EYELLUSION',\n",
       " 'kingsunglasses',\n",
       " 'kingsunglasses',\n",
       " 'ROZZETTA CRAFT',\n",
       " 'GANSTA',\n",
       " 'LIZA ANGEL',\n",
       " 'New Specs',\n",
       " 'AISLIN',\n",
       " 'VINCENT CHASE',\n",
       " 'New Specs',\n",
       " 'PIRASO',\n",
       " 'PHENOMENAL',\n",
       " 'LIZA ANGEL',\n",
       " 'SUNBEE',\n",
       " 'VINCENT CHASE',\n",
       " 'SHAAH COLLECTIONS',\n",
       " 'Fastrack',\n",
       " 'VINCENT CHASE',\n",
       " 'VINCENT CHASE',\n",
       " 'CRYSTAL CART',\n",
       " 'Sewell',\n",
       " 'Elligator',\n",
       " 'PIRASO',\n",
       " 'PIRASO',\n",
       " 'ROYAL SON',\n",
       " 'Rich Club',\n",
       " 'PIRASO',\n",
       " 'ROZZETTA CRAFT',\n",
       " 'Roadster',\n",
       " 'ROZZETTA CRAFT',\n",
       " 'Lee Topper',\n",
       " 'SRPM',\n",
       " 'ROYAL SON',\n",
       " 'PIRASO',\n",
       " 'PIRASO',\n",
       " 'New Specs',\n",
       " 'New Specs',\n",
       " 'Singco India',\n",
       " 'elegante',\n",
       " 'CRYSTAL CART',\n",
       " 'EYELLUSION',\n",
       " 'kingsunglasses',\n",
       " 'kingsunglasses',\n",
       " 'ROZZETTA CRAFT',\n",
       " 'GANSTA',\n",
       " 'LIZA ANGEL',\n",
       " 'New Specs',\n",
       " 'AISLIN',\n",
       " 'VINCENT CHASE',\n",
       " 'New Specs',\n",
       " 'PIRASO',\n",
       " 'PHENOMENAL',\n",
       " 'LIZA ANGEL',\n",
       " 'SUNBEE',\n",
       " 'VINCENT CHASE',\n",
       " 'SHAAH COLLECTIONS',\n",
       " 'Fastrack',\n",
       " 'VINCENT CHASE',\n",
       " 'VINCENT CHASE',\n",
       " 'CRYSTAL CART',\n",
       " 'Sewell',\n",
       " 'Elligator',\n",
       " 'PIRASO',\n",
       " 'PIRASO',\n",
       " 'ROYAL SON',\n",
       " 'Rich Club',\n",
       " 'PIRASO']"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B_name[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "371ffebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sun_gl=pd.DataFrame({})\n",
    "sun_gl['Brand_name']=B_name[:100]\n",
    "sun_gl['P_price']=Price_tag[:100]\n",
    "sun_gl['Pr_desc']=P_desc[:100]\n",
    "sun_gl['P_discount']=Discount[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "13e57bbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand_name</th>\n",
       "      <th>P_price</th>\n",
       "      <th>Pr_desc</th>\n",
       "      <th>P_discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AISLIN</td>\n",
       "      <td>₹448₹1,52570% off</td>\n",
       "      <td>UV Protection, Gradient Cat-eye Sunglasses (58)</td>\n",
       "      <td>70% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>₹1,049₹1,99947% off</td>\n",
       "      <td>by Lenskart Polarized, UV Protection Cat-eye S...</td>\n",
       "      <td>47% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>New Specs</td>\n",
       "      <td>₹250₹2,59990% off</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (Free Size)</td>\n",
       "      <td>90% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>₹209₹1,59986% off</td>\n",
       "      <td>UV Protection Aviator Sunglasses (54)</td>\n",
       "      <td>86% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PHENOMENAL</td>\n",
       "      <td>₹226₹99977% off</td>\n",
       "      <td>UV Protection Retro Square Sunglasses (53)</td>\n",
       "      <td>77% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>₹189₹99981% off</td>\n",
       "      <td>UV Protection Aviator Sunglasses (54)</td>\n",
       "      <td>86% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>₹268₹1,29979% off</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (52)</td>\n",
       "      <td>84% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>₹699₹1,99965% off</td>\n",
       "      <td>UV Protection, Polarized Round Sunglasses (54)</td>\n",
       "      <td>73% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Rich Club</td>\n",
       "      <td>₹185₹1,69989% off</td>\n",
       "      <td>UV Protection Retro Square Sunglasses (54)</td>\n",
       "      <td>57% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>₹639₹79920% off</td>\n",
       "      <td>UV Protection Aviator Sunglasses (58)</td>\n",
       "      <td>89% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Brand_name              P_price  \\\n",
       "0          AISLIN    ₹448₹1,52570% off   \n",
       "1   VINCENT CHASE  ₹1,049₹1,99947% off   \n",
       "2       New Specs    ₹250₹2,59990% off   \n",
       "3          PIRASO    ₹209₹1,59986% off   \n",
       "4      PHENOMENAL      ₹226₹99977% off   \n",
       "..            ...                  ...   \n",
       "95         PIRASO      ₹189₹99981% off   \n",
       "96         PIRASO    ₹268₹1,29979% off   \n",
       "97      ROYAL SON    ₹699₹1,99965% off   \n",
       "98      Rich Club    ₹185₹1,69989% off   \n",
       "99         PIRASO      ₹639₹79920% off   \n",
       "\n",
       "                                              Pr_desc P_discount  \n",
       "0     UV Protection, Gradient Cat-eye Sunglasses (58)    70% off  \n",
       "1   by Lenskart Polarized, UV Protection Cat-eye S...    47% off  \n",
       "2    UV Protection Rectangular Sunglasses (Free Size)    90% off  \n",
       "3               UV Protection Aviator Sunglasses (54)    86% off  \n",
       "4          UV Protection Retro Square Sunglasses (53)    77% off  \n",
       "..                                                ...        ...  \n",
       "95              UV Protection Aviator Sunglasses (54)    86% off  \n",
       "96          UV Protection Rectangular Sunglasses (52)    84% off  \n",
       "97     UV Protection, Polarized Round Sunglasses (54)    73% off  \n",
       "98         UV Protection Retro Square Sunglasses (54)    57% off  \n",
       "99              UV Protection Aviator Sunglasses (58)    89% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sun_gl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "7d08e471",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5)Phython program to Scrape 100 reviews data from flipkart.com for iphone11 phone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "c7733de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's first connect to the web driver\n",
    "driver =webdriver.Chrome(r\"C:\\Users\\Praveen kumar\\Downloads\\chromedriver_win32\\chromedriver.exe\")\n",
    "driver.get(\"https://www.flipkart.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "e4c5d0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "product=driver.find_element(By.CLASS_NAME,\"_3704LK\")\n",
    "product.send_keys('iphone11')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "59652239",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.CLASS_NAME,\"L0Z3Pu\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "b5fd08d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "open=driver.find_element(By.CLASS_NAME,\"_4rR01T\")\n",
    "open.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "e40d3b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_s=[]\n",
    "review_summary=[]\n",
    "full_review=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc8b0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_s= driver.find_element(By.XPATH,'/html/body/div[1]/div/div[3]/div[1]/div[2]/div[9]/div[6]/div/div[4]/div[3]/div/div/div[1]/div')\n",
    "for i in rating_s[0:10]:\n",
    " rating =i.text\n",
    "rating_s.append(rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f96636",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_summary= driver.find_elements(By.XPATH,'//p[@class=\"_2-N8zT\"]')\n",
    "for i in review_summary[0:10]:\n",
    " review =i.text\n",
    "review_summary.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae93056",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_review=driver.find_elements(By.XPATH,'//div[@class=\"t-ZTKy\"]')\n",
    "for i in full_review[0:10]:\n",
    " fullreview =i.text\n",
    "full_review.append(fullreview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27265241",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(rating_s),len(review_summary),len(full_review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff11c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame({})\n",
    "df['Rating']=rating_s[:10]\n",
    "df['Reviews']=review_summary[:10]\n",
    "df['Full review']=full_review[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "61e2bbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6)phython program to Scrape data for first 100 sneakers you find when you visit flipkart.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "019e96ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's first connect to the web driver\n",
    "driver =webdriver.Chrome(r\"C:\\Users\\Praveen kumar\\Downloads\\chromedriver_win32\\chromedriver.exe\")\n",
    "driver.get(\"https://www.flipkart.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "fb05099b",
   "metadata": {},
   "outputs": [],
   "source": [
    "product=driver.find_element(By.CLASS_NAME,\"_3704LK\")\n",
    "product.send_keys('Sneakers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "214f75c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.CLASS_NAME,\"L0Z3Pu\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "038897ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "B_name=[]\n",
    "Price=[]\n",
    "P_desc=[]\n",
    "Discount=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "ff933c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    b_name=driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')\n",
    "    p_desc=driver.find_elements(By.XPATH,'//a[@class=\"IRpwTa\"]')\n",
    "    price =driver.find_elements(By.XPATH,'//div[@class=\"_25b18c\"]')\n",
    "    discount=driver.find_elements(By.XPATH,'//div[@class=\"_3Ay6Sb\"]')\n",
    "    \n",
    "    for j  in b_name:\n",
    "        B_name.append(j.text)\n",
    "    B_name[:100]    \n",
    "    \n",
    "    \n",
    "    \n",
    "    for k in p_desc:\n",
    "        P_desc.append(k.text)\n",
    "    P_desc[:100] \n",
    "    \n",
    "    \n",
    "    for l in price:\n",
    "        Price.append(l.text)\n",
    "    Price[:100] \n",
    "    \n",
    "    \n",
    "    for t in discount:\n",
    "        Discount.append(t.text)\n",
    "    Discount[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "31807801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "100\n",
      "100\n",
      "100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None, None, None)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(B_name[:100])),print(len(Price[:100])),print(len(P_desc[:100])),print(len(Discount[:100]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "0bd9cb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sneaker_s=pd.DataFrame({})\n",
    "sneaker_s['Brand_name']=B_name[:100]\n",
    "sneaker_s['P_price']=Price[:100]\n",
    "sneaker_s['Pr_desc']=P_desc[:100]\n",
    "sneaker_s['P_discount']=Discount[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "bb34a683",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand_name</th>\n",
       "      <th>P_price</th>\n",
       "      <th>Pr_desc</th>\n",
       "      <th>P_discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Echor</td>\n",
       "      <td>₹497₹1,49966% off</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>66% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hida</td>\n",
       "      <td>₹551₹99944% off</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>44% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Shozie</td>\n",
       "      <td>₹389₹99961% off</td>\n",
       "      <td>Super Stylish &amp; Trendy Combo Pack of 02 Pairs ...</td>\n",
       "      <td>61% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chevit</td>\n",
       "      <td>₹629₹1,89866% off</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>66% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aadi</td>\n",
       "      <td>₹279₹99972% off</td>\n",
       "      <td>Lightweight Pack Of 1 Trendy Sneakers Sneakers...</td>\n",
       "      <td>72% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Shozie</td>\n",
       "      <td>₹179₹59970% off</td>\n",
       "      <td>Comfortable Premium Stylish Unique Trendy Popu...</td>\n",
       "      <td>65% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Deals4you</td>\n",
       "      <td>₹424₹99957% off</td>\n",
       "      <td>SS1100 Sneakers For Men</td>\n",
       "      <td>70% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>kardam&amp;sons</td>\n",
       "      <td>₹540₹99945% off</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>69% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Magnolia</td>\n",
       "      <td>₹299₹1,29976% off</td>\n",
       "      <td>Breathable, Walking, Running, Casual, Gym Shoe...</td>\n",
       "      <td>60% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>SCATCHITE</td>\n",
       "      <td>₹540₹99945% off</td>\n",
       "      <td>supr Sneakers For Men</td>\n",
       "      <td>63% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Brand_name            P_price  \\\n",
       "0         Echor  ₹497₹1,49966% off   \n",
       "1          Hida    ₹551₹99944% off   \n",
       "2        Shozie    ₹389₹99961% off   \n",
       "3        Chevit  ₹629₹1,89866% off   \n",
       "4          aadi    ₹279₹99972% off   \n",
       "..          ...                ...   \n",
       "95       Shozie    ₹179₹59970% off   \n",
       "96    Deals4you    ₹424₹99957% off   \n",
       "97  kardam&sons    ₹540₹99945% off   \n",
       "98     Magnolia  ₹299₹1,29976% off   \n",
       "99    SCATCHITE    ₹540₹99945% off   \n",
       "\n",
       "                                              Pr_desc P_discount  \n",
       "0                                    Sneakers For Men    66% off  \n",
       "1                                    Sneakers For Men    44% off  \n",
       "2   Super Stylish & Trendy Combo Pack of 02 Pairs ...    61% off  \n",
       "3                                    Sneakers For Men    66% off  \n",
       "4   Lightweight Pack Of 1 Trendy Sneakers Sneakers...    72% off  \n",
       "..                                                ...        ...  \n",
       "95  Comfortable Premium Stylish Unique Trendy Popu...    65% off  \n",
       "96                            SS1100 Sneakers For Men    70% off  \n",
       "97                                   Sneakers For Men    69% off  \n",
       "98  Breathable, Walking, Running, Casual, Gym Shoe...    60% off  \n",
       "99                              supr Sneakers For Men    63% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sneaker_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "1093aad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7)phython program to scrape the data from  https://www.myntra.com/shoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "ff7457fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's first connect to the web driver\n",
    "driver =webdriver.Chrome(r\"C:\\Users\\Praveen kumar\\Downloads\\chromedriver_win32\\chromedriver.exe\")\n",
    "driver.get(\"https://www.myntra.com/shoes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "3f0d7a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# appplying the price filter\n",
    "filter_button=driver.find_elements(By.XPATH,'//label[@class=\"common-customerCheckbox vertical-filters-label\"]')\n",
    "for i in filter_button:\n",
    "    if i.text==\"Rs. 6649 to Rs. 13099\":\n",
    "        i.click()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "2cd77f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying the black colur filter\n",
    "filter_button=driver.find_elements(By.XPATH,'//li[@class=\"colour-listItem\"]')\n",
    "for i in filter_button:\n",
    "    if i.text==\"Black\":\n",
    "        i.click()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "5be04af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "B_name=[]\n",
    "Price=[]\n",
    "P_desc=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "735076ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2):\n",
    "    b_name=driver.find_elements(By.XPATH,'//h1[@class=\"pdp-title\"]')\n",
    "    p_desc=driver.find_elements(By.XPATH,'//h1[@class=\"name\"]')\n",
    "    price =driver.find_elements(By.XPATH,'//div[@class=\"product-price\"]')\n",
    " \n",
    "    for j  in b_name:\n",
    "        B_name.append(j.text)\n",
    "    B_name[:100]    \n",
    "    \n",
    "    \n",
    "    \n",
    "    for k in p_desc:\n",
    "        P_desc.append(k.text)\n",
    "    P_desc[:100] \n",
    "    \n",
    "    \n",
    "    for l in price:\n",
    "        Price.append(l.text)\n",
    "    Price[:100] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "013481ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None, None)"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(B_name[:100])),print(len(Price[:100])),print(len(P_desc[:100]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "93c36bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8)phython program to scrape data from https://www.amazon.in/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "0d412127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\anaconda\\lib\\site-packages (4.4.3)\n",
      "Requirement already satisfied: urllib3[socks]~=1.26 in c:\\anaconda\\lib\\site-packages (from selenium) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\anaconda\\lib\\site-packages (from selenium) (2021.10.8)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\anaconda\\lib\\site-packages (from selenium) (0.9.2)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\anaconda\\lib\\site-packages (from selenium) (0.21.0)\n",
      "Requirement already satisfied: async-generator>=1.9 in c:\\anaconda\\lib\\site-packages (from trio~=0.17->selenium) (1.10)\n",
      "Requirement already satisfied: sortedcontainers in c:\\anaconda\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: sniffio in c:\\anaconda\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\anaconda\\lib\\site-packages (from trio~=0.17->selenium) (1.14.6)\n",
      "Requirement already satisfied: idna in c:\\anaconda\\lib\\site-packages (from trio~=0.17->selenium) (3.2)\n",
      "Requirement already satisfied: outcome in c:\\anaconda\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\anaconda\\lib\\site-packages (from trio~=0.17->selenium) (21.2.0)\n",
      "Requirement already satisfied: pycparser in c:\\anaconda\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.20)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\anaconda\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\anaconda\\lib\\site-packages (from urllib3[socks]~=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\anaconda\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.13.0)\n"
     ]
    }
   ],
   "source": [
    "# let's first install the selenium library\n",
    "! pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "39d7978f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's now import all the required libraries.\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "7d89a583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: webdriver-manager in c:\\anaconda\\lib\\site-packages (3.8.3)\n",
      "Requirement already satisfied: requests in c:\\anaconda\\lib\\site-packages (from webdriver-manager) (2.26.0)\n",
      "Requirement already satisfied: python-dotenv in c:\\anaconda\\lib\\site-packages (from webdriver-manager) (0.21.0)\n",
      "Requirement already satisfied: tqdm in c:\\anaconda\\lib\\site-packages (from webdriver-manager) (4.62.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\anaconda\\lib\\site-packages (from requests->webdriver-manager) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\anaconda\\lib\\site-packages (from requests->webdriver-manager) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\anaconda\\lib\\site-packages (from requests->webdriver-manager) (3.2)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\anaconda\\lib\\site-packages (from requests->webdriver-manager) (2.0.4)\n",
      "Requirement already satisfied: colorama in c:\\anaconda\\lib\\site-packages (from tqdm->webdriver-manager) (0.4.4)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install webdriver-manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "d67b0c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's first connect to the web driver\n",
    "driver =webdriver.Chrome(r\"C:\\Users\\Praveen kumar\\Downloads\\chromedriver_win32\\chromedriver.exe\")\n",
    "driver.get(\"https://www.amazon.in/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "e35f16b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"4df60e1ffff3c300c7f165141ae6f24c\", element=\"22ce6567-eaff-41a1-a0cf-3ac0f98356f1\")>"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finding element for job search bar\n",
    "search_g= driver.find_element(By.XPATH,'//input[@type=\"text\"]')\n",
    "search_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "2b6d1d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write on search bar\n",
    "search_g.send_keys('Laptop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "c9466b13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"4df60e1ffff3c300c7f165141ae6f24c\", element=\"b553aa37-7873-42b9-a59a-1f561e7f6a05\")>"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_btn=driver.find_element(By.XPATH,'//input[@id=\"nav-search-submit-button\"]')\n",
    "search_btn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "a4451b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_btn=driver.find_element(By.XPATH,'//input[@id=\"nav-search-submit-button\"]')\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "286d82e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu_type=driver.find_element(By.XPATH,\"/html/body/div[1]/div[2]/div[1]/div[2]/div/div[3]/span/div[1]/div/div/div[6]/ul[4]/li[11]/span/a/span\")\n",
    "cpu_type.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "fdd03a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "Title=[]\n",
    "Price=[]\n",
    "Rating=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "b4f21a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_tags=driver.find_elements(By.XPATH,'//a[@class=\"a-link-normal s-underline-text s-underline-link-text s-link-style a-text-normal\"]')\n",
    "for i in title_tags[0:10]:\n",
    " title = i.text\n",
    " Title.append(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "c9bbd8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "price_tags=driver.find_elements(By.XPATH,'//a[@class=\"a-size-base a-link-normal s-underline-text s-underline-link-text s-link-style a-text-normal\"]')\n",
    "for i in price_tags[0:10]:\n",
    " price = i.text\n",
    " Price.append(price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "c3622b99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(Price),len(Title))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "d767d0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame({})\n",
    "df['Title & rating']=Title[:10]\n",
    "df['Price']=Price[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "c591ee16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title &amp; rating</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lenovo IdeaPad Slim 5 Intel Core i7 12th Gen 1...</td>\n",
       "      <td>₹82,990\\n₹1,20,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lenovo ThinkBook 15 Intel 11th Gen Core i7 15....</td>\n",
       "      <td>₹80,790\\n₹1,24,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lenovo ThinkPad E14 Intel Core i7 11th Gen 14-...</td>\n",
       "      <td>₹94,990\\n₹1,45,800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ASUS VivoBook K15 OLED (2021), 15.6-inch FHD O...</td>\n",
       "      <td>₹82,990\\n₹1,00,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(Renewed) Lenovo Intel Core i7 5600U 12.5-Inch...</td>\n",
       "      <td>₹29,998\\n₹40,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ASUS Vivobook 15, 15.6-inch (39.62 cms) FHD, I...</td>\n",
       "      <td>₹58,990\\n₹80,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ASUS TUF Gaming F15 (2022), 15.6-inch (39.62 c...</td>\n",
       "      <td>₹1,09,990\\n₹1,44,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Lenovo Ideapad Gaming 3 Intel Core i7 10th Gen...</td>\n",
       "      <td>₹72,990\\n₹1,02,900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HP Victus 11th Gen Intel Core i7-11800H 16.1\" ...</td>\n",
       "      <td>₹1,01,490\\n₹1,25,143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Hp Pavilion X360 11Th Gen Intel Core I7 14 Inc...</td>\n",
       "      <td>₹85,990\\n₹95,900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Title & rating                 Price\n",
       "0  Lenovo IdeaPad Slim 5 Intel Core i7 12th Gen 1...    ₹82,990\\n₹1,20,990\n",
       "1  Lenovo ThinkBook 15 Intel 11th Gen Core i7 15....    ₹80,790\\n₹1,24,990\n",
       "2  Lenovo ThinkPad E14 Intel Core i7 11th Gen 14-...    ₹94,990\\n₹1,45,800\n",
       "3  ASUS VivoBook K15 OLED (2021), 15.6-inch FHD O...    ₹82,990\\n₹1,00,990\n",
       "4  (Renewed) Lenovo Intel Core i7 5600U 12.5-Inch...      ₹29,998\\n₹40,000\n",
       "5  ASUS Vivobook 15, 15.6-inch (39.62 cms) FHD, I...      ₹58,990\\n₹80,990\n",
       "6  ASUS TUF Gaming F15 (2022), 15.6-inch (39.62 c...  ₹1,09,990\\n₹1,44,990\n",
       "7  Lenovo Ideapad Gaming 3 Intel Core i7 10th Gen...    ₹72,990\\n₹1,02,900\n",
       "8  HP Victus 11th Gen Intel Core i7-11800H 16.1\" ...  ₹1,01,490\\n₹1,25,143\n",
       "9  Hp Pavilion X360 11Th Gen Intel Core I7 14 Inc...      ₹85,990\\n₹95,900"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "4a2e70de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9)python program to scrape data for first 10 job results for Data Scientist Designation in Noida location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "e7c4e2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's first connect to the web driver\n",
    "driver =webdriver.Chrome(r\"C:\\Users\\Praveen kumar\\Downloads\\chromedriver_win32\\chromedriver.exe\")\n",
    "driver.get('https://www.ambitionbox.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "bdb99ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs=driver.find_element(By.XPATH,'/html/body/div/div/div/div[1]/header/nav/ul/li[5]/a')\n",
    "jobs.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "3c5ab246",
   "metadata": {},
   "outputs": [],
   "source": [
    "designation=driver.find_element(By.XPATH,'/html/body/div/div/div/div[2]/div[1]/div[1]/div/div/div/div/span/input')\n",
    "designation.send_keys('Data scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "fe3f05a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.XPATH,'/html/body/div/div/div/div[2]/div[1]/div[1]/div/div/div/button')\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "f9e5f6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "location=driver.find_element(By.XPATH,'/html/body/div/div/div/div[2]/div[1]/div[2]/div[1]/div/div/div/div[2]/div[1]/p')\n",
    "location.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "7ba22ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "select=driver.find_element(By.XPATH,'/html/body/div/div/div/div[2]/div[1]/div[2]/div[1]/div/div/div/div[2]/div[2]/div/div[3]/div[1]/div[8]/div/label')\n",
    "select.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "8a4a981e",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title=[]\n",
    "job_location=[]\n",
    "job_posted=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "0747dfcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_tags=driver.find_elements(By.XPATH,'//div[@class=\"company-info\"]')\n",
    "for i in  title_tags[0:10]:\n",
    " title = i.text\n",
    " job_title.append(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "b41a0dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "location_tags=driver.find_elements(By.XPATH,'//div[@class=\"entity loc\"]')\n",
    "for i in  location_tags[0:10]:\n",
    " location = i.text\n",
    " job_location.append(location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "e380e6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_posted=driver.find_elements(By.XPATH,'//p[@class=\"review-count caption-strong-medium\"]')\n",
    "for i in  job_posted[0:10]:\n",
    " job = i.text\n",
    " job_posted.append(job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "f46c370d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(job_title),len(job_location),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "98ad661b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame({})\n",
    "df['Company Details']=job_title[:10]\n",
    "df['location']=job_location[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "b6703656",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Details</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Optum Global Solutions (India) Private Limited...</td>\n",
       "      <td>Noida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Optum Global Solutions (India) Private Limited...</td>\n",
       "      <td>Noida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BARCLAYS GLOBAL SERVICE CENTRE PRIVATE LIMITED...</td>\n",
       "      <td>Noida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EY GDS\\n3.8\\n(5.9k Reviews)</td>\n",
       "      <td>Gurgaon/Gurugram, Noida, Bengaluru/Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GLOBALLOGIC INDIA PRIVATE LIMITED\\n4.0\\n(2.1k ...</td>\n",
       "      <td>Nagpur, Bengaluru/Bangalore, Noida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CBRE South Asia Pvt Ltd\\n4.3\\n(2.4k Reviews)</td>\n",
       "      <td>Hyderabad/Secunderabad, Gurgaon/Gurugram, Noida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GENPACT India Private Limited\\n4.0\\n(20.2k Rev...</td>\n",
       "      <td>Noida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Genpact\\n4.0\\n(20.2k Reviews)</td>\n",
       "      <td>Noida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ericsson India Global Services Pvt. Ltd.\\n4.3\\...</td>\n",
       "      <td>Noida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Dew Solutions Pvt. Ltd.\\n4.3\\n(83 Reviews)</td>\n",
       "      <td>Gurgaon/Gurugram, Bengaluru/Bangalore, Pune +2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Company Details  \\\n",
       "0  Optum Global Solutions (India) Private Limited...   \n",
       "1  Optum Global Solutions (India) Private Limited...   \n",
       "2  BARCLAYS GLOBAL SERVICE CENTRE PRIVATE LIMITED...   \n",
       "3                        EY GDS\\n3.8\\n(5.9k Reviews)   \n",
       "4  GLOBALLOGIC INDIA PRIVATE LIMITED\\n4.0\\n(2.1k ...   \n",
       "5       CBRE South Asia Pvt Ltd\\n4.3\\n(2.4k Reviews)   \n",
       "6  GENPACT India Private Limited\\n4.0\\n(20.2k Rev...   \n",
       "7                      Genpact\\n4.0\\n(20.2k Reviews)   \n",
       "8  Ericsson India Global Services Pvt. Ltd.\\n4.3\\...   \n",
       "9         Dew Solutions Pvt. Ltd.\\n4.3\\n(83 Reviews)   \n",
       "\n",
       "                                            location  \n",
       "0                                              Noida  \n",
       "1                                              Noida  \n",
       "2                                              Noida  \n",
       "3       Gurgaon/Gurugram, Noida, Bengaluru/Bangalore  \n",
       "4                 Nagpur, Bengaluru/Bangalore, Noida  \n",
       "5    Hyderabad/Secunderabad, Gurgaon/Gurugram, Noida  \n",
       "6                                              Noida  \n",
       "7                                              Noida  \n",
       "8                                              Noida  \n",
       "9  Gurgaon/Gurugram, Bengaluru/Bangalore, Pune +2...  "
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "086bc7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#10)python program to scrape the salary data for Data Scientist designation\n",
    "#Company name, Number of salaries, Average salary, Minsalary, Max Salary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "79b48c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's first connect to the web driver\n",
    "driver =webdriver.Chrome(r\"C:\\Users\\Praveen kumar\\Downloads\\chromedriver_win32\\chromedriver.exe\")\n",
    "driver.get('https://www.ambitionbox.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "db2167cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "salaries=driver.find_element(By.XPATH,'/html/body/div/div/div/div[1]/header/nav/ul/li[3]/span')\n",
    "salaries.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "d115af62",
   "metadata": {},
   "outputs": [],
   "source": [
    "Browse_salaries=driver.find_element(By.XPATH,'/html/body/div/div/div/div[1]/header/nav/ul/li[3]/div/ul/li[1]/div/div[2]/p')\n",
    "Browse_salaries.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "36f50945",
   "metadata": {},
   "outputs": [],
   "source": [
    "designation=driver.find_element(By.XPATH,'/html/body/div/div/div/main/section[1]/div[2]/div[1]/span/input')\n",
    "designation.send_keys('Data Scientist')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "9d2f145e",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.XPATH,'/html/body/div/div/div/main/section[1]/div[2]/div[1]/i[1]')\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "43cc2229",
   "metadata": {},
   "outputs": [],
   "source": [
    "company_info=[]\n",
    "min_salary=[]\n",
    "max_salary=[]\n",
    "avg_salary=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09eb4a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    company_info=driver.find_element(By.XPATH,'/html/body/div/div/div/main/section[1]/div[2]/div[3]/div[2]/div[1]/div[1]/div/div/a\"]')\n",
    "    min_salary=driver.find_element(By.XPATH,'/html/body/div/div/div/main/section[1]/div[2]/div[3]/div[2]/div[1]/div[2]/div/div[2]/div[1]')\n",
    "    max_salary =driver.find_element(By.XPATH,'/html/body/div/div/div/main/section[1]/div[2]/div[3]/div[2]/div[1]/div[2]/div/div[2]/div[2]')\n",
    "    avg_salary=driver.find_element(By.XPATH,'/html/body/div/div/div/main/section[1]/div[2]/div[3]/div[2]/div[1]/div[2]/div/div[1]/div/p')\n",
    "    \n",
    "    for j  in company_info:\n",
    "        company_info.append(j.text)\n",
    "    company_info[:100]    \n",
    "    \n",
    "    \n",
    "    \n",
    "    for k in min_salary:\n",
    "        min_salary.append(k.text)\n",
    "    min_salary[:100] \n",
    "    \n",
    "    \n",
    "    for l in max_salary:\n",
    "        max_salary.append(l.text)\n",
    "    max_salary[:100] \n",
    "    \n",
    "    \n",
    "    for t in avg_salary:\n",
    "        avg_salary.append(t.text)\n",
    "    avg_salary[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d7ab72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
